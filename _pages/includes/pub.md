
# üìù Publications 
## Knowledge Graph


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">DASFAA 2025</div><img src='images/dhns.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Diffusion-based Hierarchical Negative Sampling for Multimodal Knowledge Graph Completion](https://arxiv.org/abs/2501.15393) \\
**Guanglin Niu**, Xiaowei Zhang

_The 30th International Conference on Database Systems for Advanced Applications (DASFAA), 2025_

- DHNS is the first to leverage the diffusion model‚Äôs capabilities within the context of multi-modal knowledge graph for negative sampling.

üìÉ[**Paper**](https://arxiv.org/pdf/2501.15393)     üíæ[**Code**](https://github.com/ngl567/DHNS) ![img](https://img.shields.io/github/stars/ngl567/DHNS?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/lcge.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Logic and Commonsense-Guided Temporal Knowledge Graph Completion](https://ojs.aaai.org/index.php/AAAI/article/view/25579) \\
**Guanglin Niu**, Bo Li

_Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2023_

  - This work LCGE is the first to introduce temporal rules into temporal knowledge graph completion models.
  - LCGE models each event from the perspectives of both the time-sensitive representation and the commonsense.
  - Our work is promoted by some forums, such as [AI TimeÈùíÂπ¥ÁßëÂ≠¶ÂÆ∂ËÆ∫Âùõ](https://mp.weixin.qq.com/s/GP_S9U4EWJD0JGZcdJO3lg).

üìÉ[**Paper**](https://ojs.aaai.org/index.php/AAAI/article/view/25579)     üíæ[**Code**](https://github.com/ngl567/LCGE) ![img](https://img.shields.io/github/stars/ngl567/LCGE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACL 2022</div><img src='images/cake.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CAKE: A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion](https://aclanthology.org/2022.acl-long.205) <strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:3fE2CSJIrl8C'></span></strong> \\
**Guanglin Niu**, Bo Li, Yongfei Zhang, Shiliang Pu

_Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (ACL), 2022_

  - This work CAKE is the first to propose a scalable knowledge graph completion framework to predict entities in a joint commonsense and fact-driven fashion.
  - CAKE generates commonsense automatically for negative sampling and multi-view link prediction.
  - Our work is promoted by several media and forums, such as [AI Time ËßÜÈ¢ë](https://www.bilibili.com/video/BV1Q44y1g78Z/) \| [AI Time Ëß£ËØª](https://mp.weixin.qq.com/s/xQ625k_2kYXerZtO6M8mGg)„ÄÅ[‰∏ìÁü•](https://www.zhuanzhi.ai/document/5648511d67d6e512eb3521ac47d763d4)„ÄÅ[Êô∫Ê∫êÁ§æÂå∫](https://hub.baai.ac.cn/view/19366)„ÄÅ[ÂºÄÊîæÁü•ËØÜÂõæË∞±](https://mp.weixin.qq.com/s/1wVS2aJd6ddyPkvZHx3Lrw)„ÄÅ[AMiner](https://www.aminer.cn/research_report/627c81397cb68b460fb6063d).

üìÉ[**Paper**](https://aclanthology.org/2022.acl-long.205.pdf)     üíæ[**Code**](https://github.com/ngl567/CAKE) ![img](https://img.shields.io/github/stars/ngl567/CAKE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">SIGIR 2021</div><img src='images/gana.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Relational Learning with Gated and Attentive Neighbor Aggregator for Few-Shot Knowledge Graph Completion](https://dl.acm.org/doi/10.1145/3404835.3462925) <strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:WF5omc3nYNoC'></span></strong> \\
**Guanglin Niu**, Yang Li, Chengguang Tang, Ruiying Geng, Jian Dai, Qiao Liu, Hao Wang, Jian Sun, Fei Huang, Luo Si

_Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR), 2021_

  - This approach GANA is the first to propose a gated and attentive neighbor aggregator to capture the most valuable contextual semantics of a relation.
  - GANA is one of the most representative models and always selected as the baseline on few-show knowledge graph completion tasks.
  - This work was conducted in collaboration with Qwen team. Our work is promoted by some media and forums, such as [‰∏ìÁü•](https://www.zhuanzhi.ai/document/01403034427fa0520e958ee1fe4afc56).

üìÉ[**Paper**](https://arxiv.org/pdf/2104.13095)     üíæ[**Code**](https://github.com/ngl567/GANA-FewShotKGC) ![img](https://img.shields.io/github/stars/ngl567/GANA-FewShotKGC?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2020</div><img src='images/rpje.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Rule-Guided Compositional Representation Learning on Knowledge Graphs](https://ojs.aaai.org//index.php/AAAI/article/view/5687)
<strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:IjCSPb-OGe4C'></span></strong> \\
**Guanglin Niu**, Yongfei Zhang, Bo Li, Peng Cui, Si Liu, Jingyang Li and Xiaowei Zhang

_Proceedings of the AAAI Conference on Artificial Intelligence (AAAI), 2020_

  - This work RPJE is the first attempt to integrate logic rules with paths for KG embedding, balancing the explainability and the generalization.
  - Our work is promoted by several media and forums, such as [ÂºÄÊîæÁü•ËØÜÂõæË∞±](https://mp.weixin.qq.com/s/tsXKwgbd2Z0XZcZZD2wcwQ)„ÄÅ[Èõ∑ÈîãÁΩë](https://www.leiphone.com/news/201912/5yfuCAlZlbFDypnH.html)„ÄÅ[SAAI](https://zhuanlan.zhihu.com/p/137519588)„ÄÅ[MLNLP](https://www.bilibili.com/video/BV1zV4y1V7j4/). Particularly, RPJE was recognized as one of the representative studies of neuro-symbolic KG reasoning at ([CCKS 2021](https://event-cdn.baai.ac.cn/live/20211228-01/Session4.mp4)).

üìÉ[**Paper**](https://ojs.aaai.org//index.php/AAAI/article/view/5687)     üíæ[**Code**](https://github.com/ngl567/RPJE) ![img](https://img.shields.io/github/stars/ngl567/RPJE?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">EMNLP 2020 Findings</div><img src='images/autoeter.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[AutoETER: Automated Entity Type Representation with Relation-Aware Attention for Knowledge Graph Embedding](https://www.aclweb.org/anthology/2020.findings-emnlp.105/)
<strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:IjCSPb-OGe4C'></span></strong> \\
**Guanglin Niu**, Yongfei Zhang, Bo Li, Shiliang Pu and Jingyang Li

_Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: Findings (EMNLP Findings), 2020_

  - This work is the first to automatically learn the embeddings of entity types to enrich the general features of entities without explicit type information.
  - Our work is promoted by some media, such as [AI Time](https://www.bilibili.com/video/BV1Q44y1g78Z/)„ÄÅ[SFFAI](https://www.bilibili.com/video/av590645807/)„ÄÅ[‰∏ìÁü•](https://mp.weixin.qq.com/s/bU6Y42250GLmXiRzi8N1Wg).

üìÉ[**Paper**](https://aclanthology.org/2020.findings-emnlp.105.pdf)     üíæ[**Code**](https://github.com/ngl567/AutoETER) ![img](https://img.shields.io/github/stars/ngl567/AutoETER?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">COLING 2022</div><img src='images/enginekg.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Perform like an Engine: A Closed-Loop Neural-Symbolic Learning Framework for Knowledge Graph Inference](https://aclanthology.org/2022.coling-1.119/)\\
**Guanglin Niu**, Bo Li, Yongfei Zhang, Shiliang Pu

_Proceedings of the 29th International Conference on Computational Linguistics (COLING), 2022_

  - EngineKG performs like a four-stroke engine in a closed-loop neural-symbolic learning framework with embedding-based rule learning and rule-enhanced knowledge graph embedding. 
  - Our work is promoted by some media and forums, such as [MLNLP Talk](https://www.bilibili.com/video/BV1zV4y1V7j4/).

üìÉ[**Paper**](https://aclanthology.org/2022.coling-1.119.pdf)     üíæ[**Code**](https://github.com/ngl567/EngineKG)
</div>
</div>


- `ËÆ°ÁÆóÊú∫ÁßëÂ≠¶ 2024` [Èù¢ÂêëÂÖ≥Á≥ªÁâπÊÄßÂª∫Ê®°ÁöÑÁü•ËØÜÂõæË∞±Ë°®Á§∫Â≠¶‰π†Á†îÁ©∂ÁªºËø∞](https://www.jsjkx.com/CN/article/openArticlePDF.jsp?id=22673), **Guanglin Niu**, Zhen Lin.
- ``Arxiv 2024`` [Knowledge Graph Embeddings: A Comprehensive Survey on Capturing Relation Properties](https://arxiv.org/pdf/2410.14733), **Guanglin Niu**. This paper is a modified English version of our article already published in Computer Science journal (in Chinese), released to facilitate communication among international researchers in the relevant fields.
- ``Arxiv 2024`` [A Pluggable Common Sense-Enhanced Framework for Knowledge Graph Completion](https://arxiv.org/pdf/2410.04488), **Guanglin Niu**, Bo Li, Siling Feng, et al.
- `Neurocomputing 2022` [Joint Semantics and Data-Driven Path Representation for Knowledge Graph Reasoning](https://www.sciencedirect.com/science/article/abs/pii/S0925231222001515), **Guanglin Niu**, Bo Li, Yongfei Zhang, et al.
- ``ACL 2021`` [Entity Concept Enhanced Few-Shot Relation Extraction](https://aclanthology.org/2021.acl-short.124/), Shan Yang, Yongfei Zhang, **Guanglin Niu**, Qinghua Zhao, et al. \| [![](https://img.shields.io/github/stars/LittleGuoKe/ConceptFERE?style=social&label=Code+Stars)](https://github.com/LittleGuoKe/ConceptFERE) <strong><span class='show_paper_citations' data='ibL7gEcAAAAJ:ufrVoPGSRksC'></span></strong>
- ``Arxiv 2021`` </span> [Path-Enhanced Multi-Relational Question Answering with Knowledge Graph Embeddings](https://arxiv.org/pdf/2110.15622.pdf), **Guanglin Niu**, Yang Li, Chengguang Tang, et al.


## üñºÔ∏è Computer Vision

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2024</div><img src='images/camel.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[CAMEL: CAusal Motion Enhancement tailored for Lifting Text-driven Video Editing](https://openaccess.thecvf.com/content/CVPR2024/html/Zhang_CAMEL_CAusal_Motion_Enhancement_Tailored_for_Lifting_Text-driven_Video_Editing_CVPR_2024_paper.html) \\
Guiwei Zhang, Tianyu Zhang, **Guanglin Niu**(Corresponding Author), Zichang Tan, Yalong Bai, Qing Yang

_Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2024_

- DHNS develops a causal motion-enhanced attention mechanism to enhance the motion coherence of latent representations while preserving content generalization to creative textual scenarios.

üìÉ[**Paper**](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_CAMEL_CAusal_Motion_Enhancement_Tailored_for_Lifting_Text-driven_Video_Editing_CVPR_2024_paper.pdf)     üíæ[**Code**](https://github.com/zhangguiwei610/CAMEL) ![img](https://img.shields.io/github/stars/zhangguiwei610/CAMEL?style=social)
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICASSP 2025</div><img src='images/idf.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Identity-aware Feature Decoupling Learning for Clothing-change Person Re-identification](https://arxiv.org/pdf/2501.05851) \\
Guiwei Zhang, Tianyu Zhang, **Guanglin Niu**(Corresponding Author), Zichang Tan, Yalong Bai, Qing Yang

_2025 IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 2025_

- IDF is the first to propose a dual-stream identity-attention model that effectively compels the network to focus comprehensively on the regions containing distinctive identity information.

üìÉ[**Paper**](https://arxiv.org/pdf/2501.05851)
</div>
</div>



- `ICLR 2023` [GeneFace: Generalized and High-Fidelity Audio-Driven 3D Talking Face Synthesis](https://openreview.net/forum?id=YfwMIDhPccD), Zhenhui Ye, Ziyue Jiang, **Yi Ren**, et al.

  
## üìö Large Language Model
- ``ACL 2023`` [AV-TranSpeech: Audio-Visual Robust Speech-to-Speech Translation](), Rongjie Huang, Huadai Liu, Xize Cheng, **Yi Ren**, et al.
- `ICLR 2023` [TranSpeech: Speech-to-Speech Translation With Bilateral Perturbation](https://openreview.net/forum?id=UVAmFAtC5ye), Rongjie Huang, Jinglin Liu, Huadai Liu, **Yi Ren**, Lichao Zhang, Jinzheng He, Zhou Zhao
- ``AAAI 2021`` [UWSpeech: Speech to Speech Translation for Unwritten Languages](https://arxiv.org/abs/2006.07926), Chen Zhang, Xu Tan, **Yi Ren**, et al. \| [**Project**](https://speechresearch.github.io/uwspeech/)
- ``IJCAI 2020`` [Task-Level Curriculum Learning for Non-Autoregressive Neural Machine Translation](https://www.ijcai.org/Proceedings/2020/0534.pdf), Jinglin Liu, **Yi Ren**, Xu Tan, et al.
- ``ACL 2020`` [SimulSpeech: End-to-End Simultaneous Speech to Text Translation](https://www.aclweb.org/anthology/2020.acl-main.350), **Yi Ren**, Jinglin Liu, Xu Tan, et al.
- ``ACL 2020`` [A Study of Non-autoregressive Model for Sequence Generation](https://arxiv.org/abs/2004.10454), **Yi Ren**, Jinglin Liu, Xu Tan, et al.
- ``ICLR 2019`` [Multilingual Neural Machine Translation with Knowledge Distillation](https://openreview.net/forum?id=S1gUsoR9YX), Xu Tan, **Yi Ren**, Di He, et al.


## Others
- ``ICLR 2022`` [Pseudo Numerical Methods for Diffusion Models on Manifolds](https://openreview.net/forum?id=PlKWVd2yBkY), Luping Liu, **Yi Ren**, Zhijie Lin, Zhou Zhao \| [![](https://img.shields.io/github/stars/luping-liu/PNDM?style=social&label=Code+Stars)](https://github.com/luping-liu/PNDM) \| [![PWC](https://img.shields.io/endpoint.svg?url=https://paperswithcode.com/badge/pseudo-numerical-methods-for-diffusion-models-1/image-generation-on-celeba-64x64)](https://paperswithcode.com/sota/image-generation-on-celeba-64x64?p=pseudo-numerical-methods-for-diffusion-models-1)
